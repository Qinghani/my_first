{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.nvidia.cn/training/\"><img src=\"https://dli-lms.s3.amazonaws.com/assets/general/DLI_Header_White.png\" width=\"400\" height=\"186\" /></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 美国手语数据集的图像分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本节中，您将使用不同的数据集 [American Sign Language](http://www.asl.gs/) 中手语字母的图像，执行在上一节中观察到的数据准备、模型创建和模型训练的步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在完成本节时，您将能够：\n",
    "* 准备图像数据进行训练\n",
    "* 创建并编译用于图像分类的简单模型\n",
    "* 训练图像分类模型并观察结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 手语数据集\n",
    "我们将使用[美国手语字母表](https://www.kaggle.com/datamunge/sign-language-mnist)图像，该字母表包含 26 个字母。其中有两个字母（j 和 z）涉及一些动作，因此已从本次训练数据集中排除。\n",
    "\n",
    "<img src=\"./images/asl.png\" style=\"width: 600px;\">\n",
    "\n",
    "### 2.2.1 Kaggle\n",
    "[Kaggle](http://www.kaggle.com) 网站提供了此数据集，此网站内容丰富，您还可在其中查找多个数据集和其他深度学习资源。除了数据集之外，内容贡献者还发布了类似于这些 notebook 的“内核”，并向您展示了如何训练模型和探索数据。如果您正在寻找新的深度学习项目以做入门之用，推荐您访问 Kaggle 网站。该网站还会在其组织的竞赛中附加一些数据集，您可以参与其中，在训练高精度模型方面与他人一较高下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个数据集无法像 MNIST 一样通过 TorchVision 加载，所以我们先学一下如何加载自定义数据。在本小节的最后，您将获得您所熟悉的`x_train`，`y_train`，`x_valid`和`y_valid`变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 读入数据\n",
    "手语数据集采用 [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) (Comma Separated Values) 格式，就是 Microsoft Excel 和 Google Sheet 采用的格式。它就是一个由行和列组成的网格，且顶部带有标签。您可以从 [train](data/asl_data/sign_mnist_train.csv) 和 [valid](data/asl_data/sign_mnist_valid.csv) 中看到。\n",
    "\n",
    "为加载和处理数据，我们将使用一个名为 [Pandas](https://pandas.pydata.org/) 的库，这是一款可供加载和处理数据的高性能工具。我们将 CSV 文件读入名为 [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) 的格式，这是 Pandas 存储数据网格所采用的格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas有一个 `read_csv` 方法，该方法将读取 csv 文件，并返回一个数据帧（Dataframe）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"data/asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 探索数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再来观察一下我们的数据。我们可以使用 [head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) 函数来抓取数据集的前几行。如您所见，每一行都是一个具有 `label` 列的图像，还有 784 个值代表该图像中的每个像素值，就像 MNIST 数据集一样。请注意，当前标签是数值，而不是字母："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 提取标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 MNIST 一样，我们希望将训练和测试标签存储在 `y_train` 和 `y_valid` 变量中。可以用 [pop](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html) 方法从 DataFrame 里删除一列并同时赋给一个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.pop('label')\n",
    "y_valid = valid_df.pop('label')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 提取图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 MNIST 一样，我们希望将训练和测试图像存储在 `x_train` 和 `x_valid` 变量中。 我们现在创建这些变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values\n",
    "x_valid = valid_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 总结训练和测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在有 27,455 张 784 像素的图像用于训练..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...及其相应的标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们有 7,172 张图片用于验证..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...及其相应的标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 数据可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将再次使用 matplotlib 库来做可视化。您无需担心此可视化的细节，但是如果您愿意，可以稍后再了解有关 [matplotlib](https://matplotlib.org/) 的更多信息。\n",
    "\n",
    "请注意，我们必须将数据从其当前的 784 像素的 1D 形状重构为 28x28 像素的 2D 形状才能合理呈现图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(40,40))\n",
    "\n",
    "num_images = 20\n",
    "for i in range(num_images):\n",
    "    row = x_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    image = row.reshape(28,28)\n",
    "    plt.subplot(1, num_images, i+1)\n",
    "    plt.title(label, fontdict={'fontsize': 30})\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 对图像数据进行归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如我们对 MNIST 数据集所做的那样，我们将对图像数据进行归一化，这意味着它们的像素值将不是介于 0 到 255 之间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...而应为 0 到 1 之间的浮点值。请使用以下单元格来完成次项工作。如果卡住了，请查看下面的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalize x_train and x_valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单击下面的'...'以显示答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# x_train = x_train / 255 is also correct\n",
    "x_train = train_df.values / 255\n",
    "x_valid = valid_df.values / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 定制数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用 PyTorch 的 [Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) 工具来创建我们自己的数据集。`__init__` 方法会在类初始化时运行一次。`__getitem__` 方法返回我们的图像和标签。\n",
    "\n",
    "由于我们的数据集足够小，我们可以将其存储在 GPU 上以加快处理速度。在之前的实验中，我们是在从每个批次中抽取数据时将其发送到 GPU。这里，我们将在 `__init__` 函数中就将数据发送到 GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_df, y_df):\n",
    "        self.xs = torch.tensor(x_df).float().to(device)\n",
    "        self.ys = torch.tensor(y_df).to(device)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        y = self.ys[idx]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义的 PyTorch 数据集的工作原理与预构建的数据集相同。它应该传递给 [DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders) 以用于模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = MyDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_N = len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = MyDataset(x_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "valid_N = len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以用下面的代码验证 DataLoader 是否按预期工作。我们会让 DataLoader 变为[可迭代](https://docs.python.org/3/library/functions.html#iter)的，然后调用 [next](https://docs.python.org/3/library/functions.html#next) 从数据中抽取第一批。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试多次运行下面的代码，每次的值应该有所不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意,每个批次有两个值。第一个是我们的 `x`，第二个是我们的 `y`。它们的第一个维度应该都有 `32` 个值，即 `batch_size`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经创建了 DataLoaders，现在是时候构建模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个练习中，我们将构建一个 sequential 模型。和之前一样，构建这样一个模型：\n",
    "\n",
    "* 有一个展平层。\n",
    "* 有一个密集的输入层。该层应包含 512 个神经元并使用 `relu` 激活函数。\n",
    "* 有第二个包含 512 个神经元的密集层，使用 `relu` 激活函数。\n",
    "* 有一个输出层，神经元数等于类别数。\n",
    "\n",
    "我们先定义一些变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "n_classes = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的单元格中完成你的工作，创建一个用于存储模型的 `model` 变量。我们已经导入了 PyTorch 的 [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) 模型类和 [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) 层类供你使用。如果需要提示，可以查看下面的解决方案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(input_size, 512),  # Input\n",
    "    nn.ReLU(),  # Activation for input\n",
    "    nn.Linear(512, 512),  # Hidden\n",
    "    nn.ReLU(),  # Activation for hidden\n",
    "    nn.Linear(512, n_classes)  # Output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次,我们将在一步内完成编译模型和将其发送到GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model.to(device))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于对这些 ASL 图像进行分类与对 MNIST 手写数字进行分类相似，我们将使用相同的`损失函数`（[Categorical CrossEntropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)）和`优化器`（[Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次，让我们更仔细地看看 `train` 和 `validate` 函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此代码与上一个笔记本中的几乎相同，但我们不再将 `x` 和 `y` 发送到 GPU，因为我们的 DataLoader 已经处理了这件事。\n",
    "\n",
    "在循环遍历 DataLoader 之前，我们将设置模型为 [model.train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train) 模式以确保其参数可以被更新。为了更容易跟踪训练进度，我们将跟踪总的`损失`和`准确率`。\n",
    "\n",
    "然后，对于 `train_loader` 中的每个批次，我们将：\n",
    "1. 从模型中获取一个`输出`预测\n",
    "2. 使用优化器的 [zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html) 函数将梯度置零\n",
    "3. 使用我们的`损失函数`计算损失\n",
    "4. 使用 [backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html) 计算梯度\n",
    "5. 使用`优化器`的 [step](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html) 函数更新我们的模型参数\n",
    "6. 更新总的`损失`和`准确率`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 验证函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型在验证期间不学习，因此 `validate` 函数比上面的 `train` 函数稍简单一些。\n",
    "\n",
    "一个关键的不同是我们将通过 [model.evaluate](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval) 将模型设置为评估模式，这将阻止模型更新任何参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            output = model(x)\n",
    "\n",
    "            loss += loss_function(output, y).item()\n",
    "            accuracy += get_batch_accuracy(output, y, valid_N)\n",
    "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.3 计算准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` 和 `validate` 函数都使用 `get_batch_accuracy`，但我们尚未在这个 notebook 中定义它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的函数有三个 `FIXME`。每个对应于函数的输入参数。你能用正确的参数替换每个 FIXME 吗?\n",
    "\n",
    "查看 [argmax](https://pytorch.org/docs/stable/generated/torch.argmax.html)，[eq](https://pytorch.org/docs/stable/generated/torch.eq.html) 和 [view_as](https://pytorch.org/docs/stable/generated/torch.Tensor.view_as.html) 文档可能会有所帮助。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = FIXME.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(FIXME.view_as(pred)).sum().item()\n",
    "    return correct / FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点击 `...` 查看答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "    return correct / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.3 训练循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们把所有内容结合起来！运行下面的单元格训练 20 个 epochs。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    train()\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.4 讨论：发生了什么？\n",
    "我们可以看到训练集上的准确率已经相当高，但验证准确率却没有那么高。您认为此处发生了什么？先思考片刻再查看下一部分的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "这是一个典型的例子，即模型学习了对训练集里的数据进行分类，但对于尚未采用的新数据进行分类的表现却并不理想。从本质上讲，这是由于模型只是在训练中记忆数据，而非真正获得对该问题（数据分类）的理解。这是一个常见的问题，称为*过拟合（overfitting）*。在接下来的两个讲座中，我们将讨论过拟合以及解决此问题的一些方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本节中，您构建了自己的神经网络来执行图像分类，取得了很不错的准确率。恭喜！\n",
    "\n",
    "到这里为止，您应该对加载数据（包括标签）、准备数据、创建模型以及使用准备好的数据训练模型的过程有所了解了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1 清理显存\n",
    "在进入下一节内容前，请先执行以下单元，以清理 GPU 显存。转至下一 notebook 之前需要执行此操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.2 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，您已经建立了几个虽然基本但还是有效的模型，您将开始学习更复杂的模型，包括*卷积神经网络*。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
